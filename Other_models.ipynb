{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxKcV-z4pAFL"
      },
      "source": [
        "# Toxic comment Analysis on Twitter tweets Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OciEBbL5o_FT",
        "outputId": "a77d3a87-b797-476c-bf30-a622fb9d65e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ranji\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\ranji\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ranji\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in c:\\users\\ranji\\anaconda3\\lib\\site-packages (0.1.68)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\ranji\\anaconda3\\lib\\site-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in c:\\users\\ranji\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in c:\\users\\ranji\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import sys  \n",
        "!{sys.executable} -m pip install contractions\n",
        "import contractions\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Train and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wSGWatjrqF6L"
      },
      "outputs": [],
      "source": [
        "\n",
        "tweets_train_dataset=pd.read_csv(\"C:/Users/ranji/Desktop/NLP/Project/twitter hate speech/Code/Dataset/FinalDataset_Train1.csv\")\n",
        "tweets_test_dataset=pd.read_csv(\"C:/Users/ranji/Desktop/NLP/Project/twitter hate speech/Code/Dataset/FinalDataset_Test1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "eyAHLdRIICWb",
        "outputId": "983b8e4f-1424-48b0-c615-e61cda08b39b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>43636</td>\n",
              "      <td>43636</td>\n",
              "      <td>1</td>\n",
              "      <td>If you tell a dyke she looks just like a nigga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6047</td>\n",
              "      <td>6047</td>\n",
              "      <td>0</td>\n",
              "      <td>i am joy. #i_am #positive #affirmation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>8555</td>\n",
              "      <td>8555</td>\n",
              "      <td>0</td>\n",
              "      <td>why the more   #actor will #book the #job from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7507</td>\n",
              "      <td>7507</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user @user i know how u feel i didn't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>29933</td>\n",
              "      <td>29933</td>\n",
              "      <td>0</td>\n",
              "      <td>trying not to shut down but maybe #pokemon wil...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  label  \\\n",
              "0           0         43636           43636      1   \n",
              "1           1          6047            6047      0   \n",
              "2           2          8555            8555      0   \n",
              "3           3          7507            7507      0   \n",
              "4           4         29933           29933      0   \n",
              "\n",
              "                                               tweet  \n",
              "0  If you tell a dyke she looks just like a nigga...  \n",
              "1        i am joy. #i_am #positive #affirmation       \n",
              "2  why the more   #actor will #book the #job from...  \n",
              "3   @user @user @user i know how u feel i didn't ...  \n",
              "4  trying not to shut down but maybe #pokemon wil...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_train_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pefd2iuwJMxy",
        "outputId": "bd82b7e2-5daa-4de3-c88a-f164d7969f64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46745</td>\n",
              "      <td>26678</td>\n",
              "      <td>26678</td>\n",
              "      <td>0</td>\n",
              "      <td>resistance.  #job   #ruiva #cacheada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46746</td>\n",
              "      <td>33358</td>\n",
              "      <td>33358</td>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#8220;@M_Rad: I'm going to miss these bitches...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46747</td>\n",
              "      <td>6249</td>\n",
              "      <td>6249</td>\n",
              "      <td>0</td>\n",
              "      <td>ð   #tech bitcoin vs. gold [infographic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46748</td>\n",
              "      <td>49095</td>\n",
              "      <td>49095</td>\n",
              "      <td>1</td>\n",
              "      <td>RT @Ronesha__: When I feel like he entertainin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46749</td>\n",
              "      <td>55583</td>\n",
              "      <td>55583</td>\n",
              "      <td>1</td>\n",
              "      <td>bitch betta get it right...shout out....ddaaaw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  label  \\\n",
              "0       46745         26678           26678      0   \n",
              "1       46746         33358           33358      1   \n",
              "2       46747          6249            6249      0   \n",
              "3       46748         49095           49095      1   \n",
              "4       46749         55583           55583      1   \n",
              "\n",
              "                                               tweet  \n",
              "0              resistance.  #job   #ruiva #cacheada   \n",
              "1  &#8220;@M_Rad: I'm going to miss these bitches...  \n",
              "2       ð   #tech bitcoin vs. gold [infographic]   \n",
              "3  RT @Ronesha__: When I feel like he entertainin...  \n",
              "4  bitch betta get it right...shout out....ddaaaw...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_test_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "hbrxxBNVWJUV",
        "outputId": "aeb0a03a-85a4-4e27-94d4-353808a2de84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='label', ylabel='count'>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Checking the Tweet Dataset Balance for Negative and Positive Tweets\n",
        "import seaborn as sns\n",
        "sns.countplot(x='label', data = tweets_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUm7lfhUZFXh"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSJPZ0q5Wcnm",
        "outputId": "474fb3b9-5605-4935-9e9d-df105f391bd3"
      },
      "outputs": [],
      "source": [
        "#Converting tweets to Bag of words format after pre-processing\n",
        "\n",
        "Bag_of_Words=[]\n",
        "for Key,Value in tweets_train_dataset.iterrows():\n",
        "    words = Value['tweet']\n",
        "    \n",
        "    expanded_words = []    \n",
        "    for word in words.split():\n",
        "      #expanding the contracted words\n",
        "      expanded_words.append(contractions.fix(word))   \n",
        "    words = ' '.join(expanded_words)\n",
        "    \n",
        "    #using regex to remove all the other special characters\n",
        "    words = re.sub(r'[^A-Za-z0-9 ]+',' ',words)\n",
        "\n",
        "    words=word_tokenize(words)\n",
        "\n",
        "    #Converting words to lower case\n",
        "    words = [w.lower() for w in words]\n",
        "    \n",
        "    #Removing stop words\n",
        "    stop_words = nltk.corpus.stopwords.words('english')\n",
        "    words = [i for i in words if not i in stop_words]\n",
        "    \n",
        "    #Converting tweets to Bag of Words\n",
        "    for k in words:\n",
        "        if k not in Bag_of_Words:\n",
        "            Bag_of_Words.append(k)\n",
        "            \n",
        "#remove the comment to check the bag of words\n",
        "#Bag_of_Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnnjHz0I5hO6",
        "outputId": "52cdb9ac-27ba-452a-f5e4-c3f152e7152b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of Words: 56732\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of Words:\",len(Bag_of_Words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xs1z3QzU5nGq"
      },
      "outputs": [],
      "source": [
        "#Creating copies of Bag of words for Count and TF-IDF Vectorizer\n",
        "Count_Bag_of_Words = Bag_of_Words.copy()\n",
        "TF_IDF_Bag_of_Words = Bag_of_Words.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WtpZ86Zp6Vri"
      },
      "outputs": [],
      "source": [
        "#Initializing Vectorizers\n",
        "Count_Vector_tweets = CountVectorizer()\n",
        "Count_Vector_tweets = Count_Vector_tweets.fit(Count_Bag_of_Words)\n",
        "\n",
        "TF_IDF_Vector_tweets= TfidfVectorizer()\n",
        "TF_IDF_Vector_tweets = TF_IDF_Vector_tweets.fit(TF_IDF_Bag_of_Words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hnh59c387d6O"
      },
      "outputs": [],
      "source": [
        "#Train data for Count Vectorizer\n",
        "Count_X = tweets_train_dataset['tweet']\n",
        "Count_Y = tweets_train_dataset['label']\n",
        "Count_X = np.array(Count_X)\n",
        "Count_Y = np.array(Count_Y)\n",
        "\n",
        "#Train data for TF_IDF Vectorizer\n",
        "TF_IDF_X = tweets_train_dataset['tweet']\n",
        "TF_IDF_Y = tweets_train_dataset['label']\n",
        "TF_IDF_X = np.array(TF_IDF_X)\n",
        "TF_IDF_Y = np.array(TF_IDF_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oZRqwnGz9wIU"
      },
      "outputs": [],
      "source": [
        "#Defining Models to Train & Test the Dataset\n",
        "\n",
        "def Machine_Learning_Models(Vector_tweets,X_train,y_train,X_test,y_test,train_accuracy):\n",
        "    Final_pred= Vector_tweets.transform(X_train)\n",
        "    Final_pred\n",
        "    Accuracies_of_All_methods = []\n",
        "    Knn = KNeighborsClassifier(n_neighbors=1)\n",
        "    Knn.fit(Final_pred,y_train)\n",
        "    X_test = Vector_tweets.transform(X_test)\n",
        "    prediction = Knn.predict(X_test)\n",
        "    Accuracies_of_All_methods.append(accuracy_score(y_test,prediction))\n",
        "    if train_accuracy == 1:\n",
        "        print(\"K-Nearest Neighbor Classifier done\")\n",
        "    else:\n",
        "        print(\"K-Nearest Neighbor Classifier :-\")\n",
        "        print(\"Confusion Matrix\")\n",
        "        print(confusion_matrix(y_test,prediction))\n",
        "        print(\"Classification Report\")\n",
        "        print(classification_report(y_test,prediction))\n",
        "    \n",
        "    Support_Vector_Machine = SVC()\n",
        "    Support_Vector_Machine.fit(Final_pred,y_train)\n",
        "    prediction = Support_Vector_Machine.predict(X_test)\n",
        "    Accuracies_of_All_methods.append(accuracy_score(y_test,prediction))\n",
        "    if train_accuracy == 1:\n",
        "        print(\"Support Vector Machine Classifier done\")\n",
        "    else:\n",
        "        print(\"Support Vector Machine Classifier :-\")\n",
        "        print(\"Confusion Matrix\")\n",
        "        print(confusion_matrix(y_test,prediction))\n",
        "        print(\"Classification Report\")\n",
        "        print(classification_report(y_test,prediction))\n",
        "    \n",
        "    Multinomial_Naive_Bayes = MultinomialNB()\n",
        "    Multinomial_Naive_Bayes.fit(Final_pred,y_train)\n",
        "    prediction = Multinomial_Naive_Bayes.predict(X_test)\n",
        "    Accuracies_of_All_methods.append(accuracy_score(y_test,prediction))\n",
        "    if train_accuracy == 1:\n",
        "        print(\"Multinomial Naive Bayes classifier done\")\n",
        "    else:\n",
        "        print(\"Multinomial Naive Bayes classifier :-\")\n",
        "        print(\"Confusion Matrix\")\n",
        "        print(confusion_matrix(y_test,prediction))\n",
        "        print(\"Classification Report\")\n",
        "        print(classification_report(y_test,prediction))\n",
        "    \n",
        "    # Logistic Regression Classifier\n",
        "    Logistic_Regression = LogisticRegression()\n",
        "    Logistic_Regression.fit(Final_pred,y_train)\n",
        "    prediction = Logistic_Regression.predict(X_test)\n",
        "    Accuracies_of_All_methods.append(accuracy_score(y_test,prediction))\n",
        "    if train_accuracy == 1:\n",
        "        print(\"Logistic Regression Classifier done\")\n",
        "        return Accuracies_of_All_methods\n",
        "    else:\n",
        "        print(\"Logistic Regression Classifier :-\")\n",
        "        print(\"Confusion Matrix\")\n",
        "        print(confusion_matrix(y_test,prediction))\n",
        "        print(\"Classification Report\")\n",
        "        print(classification_report(y_test,prediction))\n",
        "    print(\"Test Accuracy of Models:-\")\n",
        "    print(\"KNN : \",Accuracies_of_All_methods[0])\n",
        "    print(\"SVM : \",Accuracies_of_All_methods[1])\n",
        "    print(\"Naive Bayes : \",Accuracies_of_All_methods[2])\n",
        "    print(\"Logistic Regression : \",Accuracies_of_All_methods[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZNjc1VE90-s",
        "outputId": "02f73b23-1e08-4eb6-f592-3b73b6500a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "Fold1\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.8154882875173816, 0.9423467750561557, 0.918921809819232, 0.9452347844689272]\n",
            "TF-IDF Vectorizer\n",
            "\n",
            "Fold1\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.6724783399294042, 0.9420258851214034, 0.9239490854636859, 0.9328270403251685]\n"
          ]
        }
      ],
      "source": [
        "# 5 Fold cross validation is implemented to find testing accuracy\n",
        "\n",
        "# Fold 1 for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "print(\"Fold1\")\n",
        "Count_X_train1 = Count_X[9349:]\n",
        "Count_Y_train1 = Count_Y[9349:]\n",
        "Count_X_val1 = Count_X[:9349]\n",
        "Count_Y_val1 = Count_Y[:9349]\n",
        "\n",
        "Count_fold1 = Machine_Learning_Models(Count_Vector_tweets,Count_X_train1, Count_Y_train1, Count_X_val1, Count_Y_val1,1)\n",
        "\n",
        "print(Count_fold1)\n",
        "\n",
        "# Fold 1 for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "print(\"Fold1\")\n",
        "TF_IDF_X_train1 = TF_IDF_X[9349:]\n",
        "TF_IDF_Y_train1 = TF_IDF_Y[9349:]\n",
        "TF_IDF_X_val1 = TF_IDF_X[:9349]\n",
        "TF_IDF_Y_val1 = TF_IDF_Y[:9349]\n",
        "\n",
        "TF_IDF_fold1 = Machine_Learning_Models(TF_IDF_Vector_tweets,TF_IDF_X_train1, TF_IDF_Y_train1, TF_IDF_X_val1, TF_IDF_Y_val1,1)\n",
        "print(TF_IDF_fold1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXrHOA00-6lm",
        "outputId": "e6e3e8e9-860c-4d24-b0b1-4c5d5102500a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "Fold 2\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.8879024494598353, 0.9399935822013049, 0.9172103968338859, 0.9422398117445716]\n",
            "TF-IDF Vectorizer\n",
            "\n",
            "Fold 2\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.7746283024922451, 0.9396726922665526, 0.9202053695582415, 0.9318643705209113]\n"
          ]
        }
      ],
      "source": [
        "# Fold 2 for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "print(\"Fold 2\")\n",
        "Count_fold2= []\n",
        "Count_X_train2 = np.concatenate((Count_X[:9349], Count_X[18698:]), axis=0)\n",
        "Count_Y_train2 = np.concatenate((Count_Y[:9349], Count_Y[18698:]), axis=0)\n",
        "Count_X_val2 = Count_X[9349:18698]\n",
        "Count_Y_val2 = Count_Y[9349:18698]\n",
        "\n",
        "Count_fold2 = Machine_Learning_Models(Count_Vector_tweets,Count_X_train2, Count_Y_train2, Count_X_val2, Count_Y_val2,1)\n",
        "print(Count_fold2)\n",
        "\n",
        "# Fold 2 for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "print(\"Fold 2\")\n",
        "fold2= []\n",
        "TF_IDF_X_train2 = np.concatenate((TF_IDF_X[:9349], TF_IDF_X[18698:]), axis=0)\n",
        "TF_IDF_Y_train2 = np.concatenate((TF_IDF_Y[:9349], TF_IDF_Y[18698:]), axis=0)\n",
        "TF_IDF_X_val2 = TF_IDF_X[9349:18698]\n",
        "TF_IDF_Y_val2 = TF_IDF_Y[9349:18698]\n",
        "\n",
        "TF_IDF_fold2 = Machine_Learning_Models(TF_IDF_Vector_tweets,TF_IDF_X_train2, TF_IDF_Y_train2, TF_IDF_X_val2, TF_IDF_Y_val2,1)\n",
        "print(TF_IDF_fold2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_9vbeM-7am",
        "outputId": "74219f3d-316d-4395-90b6-d44fd4dd2be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "Fold 3\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.8870467429671622, 0.9368916461653652, 0.9132527543052733, 0.9414910685634827]\n",
            "TF-IDF Vectorizer\n",
            "\n",
            "Fold 3\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.766819980746604, 0.9371055727885336, 0.9168895068991336, 0.929939030912397]\n"
          ]
        }
      ],
      "source": [
        "# Fold 3 for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "print(\"Fold 3\")\n",
        "Count_fold3= []\n",
        "Count_X_train3 = np.concatenate((Count_X[:18698], Count_X[28047:]), axis=0)\n",
        "Count_Y_train3 = np.concatenate((Count_Y[:18698], Count_Y[28047:]), axis=0)\n",
        "Count_X_val3 = Count_X[18698:28047]\n",
        "Count_Y_val3 = Count_Y[18698:28047]\n",
        "\n",
        "Count_fold3 = Machine_Learning_Models(Count_Vector_tweets,Count_X_train3, Count_Y_train3, Count_X_val3, Count_Y_val3,1)\n",
        "print(Count_fold3)\n",
        "\n",
        "# Fold 3 for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "print(\"Fold 3\")\n",
        "TF_IDF_fold3= []\n",
        "TF_IDF_X_train3 = np.concatenate((TF_IDF_X[:18698], TF_IDF_X[28047:]), axis=0)\n",
        "TF_IDF_Y_train3 = np.concatenate((TF_IDF_Y[:18698], TF_IDF_Y[28047:]), axis=0)\n",
        "TF_IDF_X_val3 = TF_IDF_X[18698:28047]\n",
        "TF_IDF_Y_val3 = TF_IDF_Y[18698:28047]\n",
        "\n",
        "TF_IDF_fold3 = Machine_Learning_Models(TF_IDF_Vector_tweets,TF_IDF_X_train3, TF_IDF_Y_train3, TF_IDF_X_val3, TF_IDF_Y_val3,1)\n",
        "print(TF_IDF_fold3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Egi8l_R--LY",
        "outputId": "3962ffa3-e66e-471a-c372-5aaf7243a453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "Fold 4\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.8950689913359717, 0.9396726922665526, 0.9225585624130923, 0.9461974542731842]\n",
            "TF-IDF Vectorizer\n",
            "\n",
            "TF_IDF_Fold 4\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.7738795593111563, 0.9411701786287303, 0.925660498449032, 0.9328270403251685]\n"
          ]
        }
      ],
      "source": [
        "# Fold 4 for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "print(\"Fold 4\")\n",
        "Count_fold4= []\n",
        "Count_X_train4 = np.concatenate((Count_X[:28047], Count_X[37396:]), axis=0)\n",
        "Count_Y_train4 = np.concatenate((Count_Y[:28047], Count_Y[37396:]), axis=0)\n",
        "Count_X_val4 = Count_X[28047:37396]\n",
        "Count_Y_val4 = Count_Y[28047:37396]\n",
        "\n",
        "Count_fold4 = Machine_Learning_Models(Count_Vector_tweets,Count_X_train4, Count_Y_train4, Count_X_val4, Count_Y_val4,1)\n",
        "print(Count_fold4)\n",
        "\n",
        "# Fold 4 for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "print(\"TF_IDF_Fold 4\")\n",
        "TF_IDF_fold4= []\n",
        "TF_IDF_X_train4 = np.concatenate((TF_IDF_X[:28047], TF_IDF_X[37396:]), axis=0)\n",
        "TF_IDF_Y_train4 = np.concatenate((TF_IDF_Y[:28047], TF_IDF_Y[37396:]), axis=0)\n",
        "TF_IDF_X_val4 = TF_IDF_X[28047:37396]\n",
        "TF_IDF_Y_val4 = TF_IDF_Y[28047:37396]\n",
        "\n",
        "TF_IDF_fold4 = Machine_Learning_Models(TF_IDF_Vector_tweets, TF_IDF_X_train4, TF_IDF_Y_train4, TF_IDF_X_val4, TF_IDF_Y_val4,1)\n",
        "print(TF_IDF_fold4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O3B-QoJK_Bw_",
        "outputId": "1d7321b7-dfa3-40f1-cc07-89e7ea12191e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "Fold 5\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.8938923949085463, 0.9435233714835811, 0.9242699753984384, 0.9473740507006096]\n",
            "TF-IDF Vectorizer\n",
            "\n",
            "TF_IDF_Fold 5\n",
            "K-Nearest Neighbor Classifier done\n",
            "Support Vector Machine Classifier done\n",
            "Multinomial Naive Bayes classifier done\n",
            "Logistic Regression Classifier done\n",
            "[0.7758048989196705, 0.9430955182372446, 0.9266231682532892, 0.9336827468178415]\n"
          ]
        }
      ],
      "source": [
        "# Fold 5 for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "print(\"Fold 5\")\n",
        "Count_X_train5 = Count_X[:37396]\n",
        "Count_Y_train5 = Count_Y[:37396]\n",
        "Count_X_val5 = Count_X[37396:]\n",
        "Count_Y_val5 = Count_Y[37396:]\n",
        "\n",
        "Count_fold5 = Machine_Learning_Models(Count_Vector_tweets, Count_X_train5, Count_Y_train5, Count_X_val5, Count_Y_val5,1)\n",
        "print(Count_fold5)\n",
        "\n",
        "# Fold 5 for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "print(\"TF_IDF_Fold 5\")\n",
        "TF_IDF_X_train5 = TF_IDF_X[:37396]\n",
        "TF_IDF_Y_train5 = TF_IDF_Y[:37396]\n",
        "TF_IDF_X_val5 = TF_IDF_X[37396:]\n",
        "TF_IDF_Y_val5 = TF_IDF_Y[37396:]\n",
        "\n",
        "TF_IDF_fold5 = Machine_Learning_Models(TF_IDF_Vector_tweets, TF_IDF_X_train5, TF_IDF_Y_train5, TF_IDF_X_val5, TF_IDF_Y_val5,1)\n",
        "print(TF_IDF_fold5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models Evaluation and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hr6G5XSZ_Hhy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer Accurary for Different Models:\n",
            "\n",
            "Average Training accuracy of KNN: 0.8758797732377793\n",
            "Average Training accuracy of SVM: 0.9043130898409538\n",
            "Average Training accuracy of Naive Bayes: 0.9192426997539844\n",
            "Average Training accuracy of Logistic Regression: 0.9081802249520721\n",
            "\n",
            "\n",
            "TF-IDF Vectorizer Accurary for Different Models:\n",
            "\n",
            "Average Training accuracy of KNN: 0.752722216279816\n",
            "Average Training accuracy of SVM: 0.9044365090466278\n",
            "Average Training accuracy of Naive Bayes: 0.9226655257246763\n",
            "Average Training accuracy of Logistic Regression: 0.9139490644904879\n"
          ]
        }
      ],
      "source": [
        "print(\"Count Vectorizer Accurary for Different Models:\\n\")\n",
        "print(\"Average Training accuracy of KNN:\", (Count_fold1[0]+Count_fold2[0]+Count_fold3[0]+Count_fold4[0]+Count_fold5[0])/5)\n",
        "print(\"Average Training accuracy of SVM:\", (Count_fold1[1]+Count_fold2[1]+Count_fold3[1]+Count_fold4[1]+Count_fold5[1])/5)\n",
        "print(\"Average Training accuracy of Naive Bayes:\", (Count_fold1[2]+Count_fold2[2]+Count_fold3[2]+Count_fold4[2]+Count_fold5[2])/5)\n",
        "print(\"Average Training accuracy of Logistic Regression:\", (Count_fold1[3]+Count_fold2[3]+Count_fold3[3]+Count_fold4[3]+Count_fold5[3])/5)\n",
        "\n",
        "print(\"\\n\\nTF-IDF Vectorizer Accurary for Different Models:\\n\")\n",
        "print(\"Average Training accuracy of KNN:\", (TF_IDF_fold1[0]+TF_IDF_fold2[0]+TF_IDF_fold3[0]+TF_IDF_fold4[0]+TF_IDF_fold5[0])/5)\n",
        "print(\"Average Training accuracy of SVM:\", (TF_IDF_fold1[1]+TF_IDF_fold2[1]+TF_IDF_fold3[1]+TF_IDF_fold4[1]+TF_IDF_fold5[1])/5)\n",
        "print(\"Average Training accuracy of Naive Bayes:\", (TF_IDF_fold1[2]+TF_IDF_fold2[2]+TF_IDF_fold3[2]+TF_IDF_fold4[2]+TF_IDF_fold5[2])/5)\n",
        "print(\"Average Training accuracy of Logistic Regression:\", (TF_IDF_fold1[3]+TF_IDF_fold2[3]+TF_IDF_fold3[3]+TF_IDF_fold4[3]+TF_IDF_fold5[3])/5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xGVD9Owp_Ji1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count Vectorizer\n",
            "\n",
            "TF-IDF Vectorizer\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test dataset taken to calculate Test accuracy for Count Vectorizer\n",
        "print(\"Count Vectorizer\\n\")\n",
        "Count_X_test = tweets_test_dataset['tweet']\n",
        "Count_y_test = tweets_test_dataset['label']\n",
        "\n",
        "# Test dataset taken to calculate Test accuracy for TF-IDF Vectorizer\n",
        "print(\"TF-IDF Vectorizer\\n\")\n",
        "TF_IDF_X_test = tweets_test_dataset['tweet']\n",
        "TF_IDF_y_test = tweets_test_dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hHmDbUv_LL_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the Models trained using Count Vectorizer\n",
            "K-Nearest Neighbor Classifier :-\n",
            "Confusion Matrix\n",
            "[[5460  279]\n",
            " [ 776 3485]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      5739\n",
            "           1       0.93      0.82      0.87      4261\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.90      0.88      0.89     10000\n",
            "weighted avg       0.90      0.89      0.89     10000\n",
            "\n",
            "Support Vector Machine Classifier :-\n",
            "Confusion Matrix\n",
            "[[5596  143]\n",
            " [ 430 3831]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      5739\n",
            "           1       0.96      0.90      0.93      4261\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.95      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n",
            "Multinomial Naive Bayes classifier :-\n",
            "Confusion Matrix\n",
            "[[5228  511]\n",
            " [ 339 3922]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92      5739\n",
            "           1       0.88      0.92      0.90      4261\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.91      0.92      0.91     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "Logistic Regression Classifier :-\n",
            "Confusion Matrix\n",
            "[[5586  153]\n",
            " [ 385 3876]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      5739\n",
            "           1       0.96      0.91      0.94      4261\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.94      0.94     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n",
            "Test Accuracy of Models:-\n",
            "KNN :  0.8945\n",
            "SVM :  0.9427\n",
            "Naive Bayes :  0.915\n",
            "Logistic Regression :  0.9462\n",
            "Testing the Models trained using TF-IDF Vectorizer\n",
            "K-Nearest Neighbor Classifier :-\n",
            "Confusion Matrix\n",
            "[[5570  169]\n",
            " [1841 2420]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.97      0.85      5739\n",
            "           1       0.93      0.57      0.71      4261\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.84      0.77      0.78     10000\n",
            "weighted avg       0.83      0.80      0.79     10000\n",
            "\n",
            "Support Vector Machine Classifier :-\n",
            "Confusion Matrix\n",
            "[[5590  149]\n",
            " [ 432 3829]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      5739\n",
            "           1       0.96      0.90      0.93      4261\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.95      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n",
            "Multinomial Naive Bayes classifier :-\n",
            "Confusion Matrix\n",
            "[[5347  392]\n",
            " [ 430 3831]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      5739\n",
            "           1       0.91      0.90      0.90      4261\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "Logistic Regression Classifier :-\n",
            "Confusion Matrix\n",
            "[[5565  174]\n",
            " [ 519 3742]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94      5739\n",
            "           1       0.96      0.88      0.92      4261\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.94      0.92      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "Test Accuracy of Models:-\n",
            "KNN :  0.799\n",
            "SVM :  0.9419\n",
            "Naive Bayes :  0.9178\n",
            "Logistic Regression :  0.9307\n"
          ]
        }
      ],
      "source": [
        "#Testing the Count Vectorizer Model\n",
        "\n",
        "print(\"Testing the Models trained using Count Vectorizer\")\n",
        "Machine_Learning_Models(Count_Vector_tweets,Count_X,Count_Y,Count_X_test,Count_y_test,0) \n",
        "\n",
        "\n",
        "\n",
        "#Testing the TF-IDF Vectorizer Model\n",
        "\n",
        "print(\"Testing the Models trained using TF-IDF Vectorizer\")\n",
        "Machine_Learning_Models(TF_IDF_Vector_tweets,TF_IDF_X,TF_IDF_Y,TF_IDF_X_test,TF_IDF_y_test,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hate Speech Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
